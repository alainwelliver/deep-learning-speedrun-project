
================================================================================
NANOGPT EXPERIMENT LOG
================================================================================
Experiment Name: nanogpt_baseline
Start Time: 2025-12-09T15:55:06.753767

GIT INFORMATION:
  Commit:  99352aac39f7798169e163db866987ab1956a981
  Branch:  main
  Remote:  https://github.com/alainwelliver/deep-learning-speedrun-project.git
  Dirty:   True

GPU INFORMATION:
  CUDA Available: True
  Device Count:   8
  CUDA Version:   12.8
  PyTorch:        2.8.0+cu128
  Device 0: NVIDIA H100 PCIe (85.0 GB)
  Device 1: NVIDIA H100 PCIe (85.0 GB)
  Device 2: NVIDIA H100 PCIe (85.0 GB)
  Device 3: NVIDIA H100 PCIe (85.0 GB)
  Device 4: NVIDIA H100 PCIe (85.0 GB)
  Device 5: NVIDIA H100 PCIe (85.0 GB)
  Device 6: NVIDIA H100 PCIe (85.0 GB)
  Device 7: NVIDIA H100 PCIe (85.0 GB)

================================================================================

[2025-12-09 15:55:06.754] [INFO] Starting experiment: nanogpt_baseline
[2025-12-09 15:55:06.754] [INFO] Configuration file: configs/stage_c_full/baseline.json
[2025-12-09 15:55:06.754] [INFO] Training script: experiments/train_gpt.py
[2025-12-09 15:55:06.754] [INFO] Number of GPUs: 8
[2025-12-09 15:55:06.754] [WARNING] WARNING: GPU count overridden from 8 to 8
[2025-12-09 15:55:06.754] [INFO] Number of runs: 1
[2025-12-09 15:55:06.754] [INFO] Base seed: 42
[2025-12-09 15:55:06.754] [INFO] Description: Stage C: Baseline NanoGPT training - full run (5100 iters, 8 H100s)
[2025-12-09 15:55:06.754] [INFO] Target validation loss: 3.28
[2025-12-09 15:55:06.754] [INFO] Configuration saved to config.json
[2025-12-09 15:55:06.754] [INFO] Configuration: {
  "experiment_name": "nanogpt_baseline",
  "description": "Stage C: Baseline NanoGPT training - full run (5100 iters, 8 H100s)",
  "script": "experiments/train_gpt.py",
  "stage": "C_full",
  "n_gpus": 8,
  "base_seed": 42,
  "target_val_loss": 3.28,
  "modification_type": "none",
  "stage_config": {
    "recommended_runs": 5,
    "notes": "Full training (5100 iters) - uses default hyperparameters from training script"
  },
  "hyperparameters": {
    "batch_size": 512,
    "device_batch_size": 64,
    "sequence_length": 1024,
    "num_iterations": 5100,
    "learning_rate": 0.0036,
    "warmup_iters": 0,
    "warmdown_iters": 1450,
    "weight_decay": 0,
    "val_loss_every": 125,
    "val_tokens": 10485760,
    "notes": "Using default hyperparameters from train_gpt.py Hyperparameters dataclass"
  }
}
[2025-12-09 15:55:06.754] [INFO] ================================================================================
[2025-12-09 15:55:06.754] [INFO] DRY RUN MODE - No actual training will be performed
[2025-12-09 15:55:06.754] [INFO] ================================================================================
[2025-12-09 15:55:06.754] [INFO] ================================================================================
[2025-12-09 15:55:06.755] [INFO] Starting 1 training runs...
[2025-12-09 15:55:06.755] [INFO] ================================================================================
[2025-12-09 15:55:06.755] [INFO] Starting run 0 with seed 42
[2025-12-09 15:55:06.755] [INFO] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2025-12-09 15:55:06.755] [INFO] DRY RUN - Would execute: torchrun --standalone --nproc_per_node=8 experiments/train_gpt.py
[2025-12-09 15:55:06.755] [INFO] DRY RUN - With environment: RUN_SEED=42
[2025-12-09 15:55:06.755] [INFO] Progress: 1/1 runs completed (1 successful)
[2025-12-09 15:55:06.755] [INFO] --------------------------------------------------------------------------------
[2025-12-09 15:55:06.755] [INFO] ================================================================================
[2025-12-09 15:55:06.755] [INFO] All runs completed: 1/1 successful
[2025-12-09 15:55:06.755] [INFO] ================================================================================
[2025-12-09 15:55:06.755] [INFO] Computing statistics...
[2025-12-09 15:55:06.755] [INFO] ================================================================================
[2025-12-09 15:55:06.755] [INFO] FINALIZING EXPERIMENT
[2025-12-09 15:55:06.755] [INFO] ================================================================================
[2025-12-09 15:55:06.755] [INFO] Experiment completed with 0 runs
[2025-12-09 15:55:06.755] [INFO] Successful runs: 0
[2025-12-09 15:55:06.755] [INFO] Failed runs: 0
[2025-12-09 15:55:06.756] [INFO] Summary saved to summary.json
[2025-12-09 15:55:06.756] [INFO] End Time: 2025-12-09 15:55:06.756308
[2025-12-09 15:55:06.756] [INFO] ================================================================================
