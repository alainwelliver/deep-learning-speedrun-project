
================================================================================
NANOGPT EXPERIMENT LOG
================================================================================
Experiment Name: nanogpt_baseline_screening
Start Time: 2025-12-08T16:23:21.292474

GIT INFORMATION:
  Commit:  a8ac360eb39e396a9452c517c223bdcf70d6259f
  Branch:  main
  Remote:  https://github.com/alainwelliver/deep-learning-speedrun-project.git
  Dirty:   True

GPU INFORMATION:
  CUDA Available: True
  Device Count:   1
  CUDA Version:   12.8
  PyTorch:        2.8.0+cu128
  Device 0: NVIDIA L40 (47.6 GB)

================================================================================

[2025-12-08 16:23:21.292] [INFO] Starting experiment: nanogpt_baseline_screening
[2025-12-08 16:23:21.293] [INFO] Configuration file: configs/stage_a_screening/baseline_screening.json
[2025-12-08 16:23:21.293] [INFO] Training script: experiments/train_gpt.py
[2025-12-08 16:23:21.293] [INFO] Number of GPUs: 1
[2025-12-08 16:23:21.293] [WARNING] WARNING: GPU count overridden from 1 to 1
[2025-12-08 16:23:21.293] [INFO] Number of runs: 1
[2025-12-08 16:23:21.293] [INFO] Base seed: 42
[2025-12-08 16:23:21.293] [INFO] Description: Stage A: Baseline screening run (1000 iters, 1 L40)
[2025-12-08 16:23:21.293] [INFO] Target validation loss: 3.5
[2025-12-08 16:23:21.293] [INFO] Configuration saved to config.json
[2025-12-08 16:23:21.294] [INFO] Configuration: {
  "experiment_name": "nanogpt_baseline_screening",
  "description": "Stage A: Baseline screening run (1000 iters, 1 L40)",
  "script": "experiments/train_gpt.py",
  "stage": "A_screening",
  "n_gpus": 1,
  "base_seed": 42,
  "target_val_loss": 3.5,
  "modification_type": "none",
  "stage_config": {
    "num_iterations": 1000,
    "warmdown_iters": 284,
    "batch_size": 128,
    "device_batch_size": 16,
    "val_loss_every": 25,
    "recommended_runs": 2,
    "notes": "~1/5 of full training (1000/5100 iters), batch scaled for 1 GPU"
  },
  "hyperparameters": {
    "batch_size": 128,
    "device_batch_size": 16,
    "sequence_length": 1024,
    "num_iterations": 1000,
    "learning_rate": 0.0036,
    "warmup_iters": 0,
    "warmdown_iters": 284,
    "weight_decay": 0,
    "val_loss_every": 25,
    "val_tokens": 10485760
  }
}
[2025-12-08 16:23:21.294] [INFO] ================================================================================
[2025-12-08 16:23:21.294] [INFO] Starting 1 training runs...
[2025-12-08 16:23:21.294] [INFO] ================================================================================
[2025-12-08 16:23:21.294] [INFO] Starting run 0 with seed 42
[2025-12-08 16:23:21.295] [INFO] Running: torchrun --standalone --nproc_per_node=1 experiments/train_gpt.py
[2025-12-08 16:23:21.295] [INFO] Working directory: /deep-learning-speedrun-project/nanogpt
[2025-12-08 16:23:21.295] [INFO] Stdout log: experiment_logs/nanogpt_baseline_screening_20251208_162321/runs/run_0_seed_42/stdout.log
[2025-12-08 16:28:21.520] [INFO] Run 0 - Step 25: val_loss=6.4601
[2025-12-08 16:29:34.381] [INFO] Run 0 - Step 50: val_loss=6.0525
[2025-12-08 16:30:47.802] [INFO] Run 0 - Step 75: val_loss=5.7600
[2025-12-08 16:32:01.154] [INFO] Run 0 - Step 100: val_loss=5.5294
[2025-12-08 16:33:14.293] [INFO] Run 0 - Step 125: val_loss=5.3580
[2025-12-08 16:34:27.264] [INFO] Run 0 - Step 150: val_loss=5.2173
[2025-12-08 16:35:39.697] [INFO] Run 0 - Step 175: val_loss=5.0956
[2025-12-08 16:36:51.544] [INFO] Run 0 - Step 200: val_loss=5.0046
[2025-12-08 16:38:03.242] [INFO] Run 0 - Step 225: val_loss=4.9154
[2025-12-08 16:39:14.878] [INFO] Run 0 - Step 250: val_loss=4.8219
[2025-12-08 16:40:26.401] [INFO] Run 0 - Step 275: val_loss=4.7424
[2025-12-08 16:41:38.274] [INFO] Run 0 - Step 300: val_loss=4.6423
[2025-12-08 16:42:50.475] [INFO] Run 0 - Step 325: val_loss=4.5807
[2025-12-08 16:44:02.646] [INFO] Run 0 - Step 350: val_loss=4.5087
[2025-12-08 16:45:14.737] [INFO] Run 0 - Step 375: val_loss=4.4603
[2025-12-08 16:46:26.738] [INFO] Run 0 - Step 400: val_loss=4.4197
[2025-12-08 16:47:38.667] [INFO] Run 0 - Step 425: val_loss=4.3900
[2025-12-08 16:48:50.537] [INFO] Run 0 - Step 450: val_loss=4.3471
[2025-12-08 16:50:02.347] [INFO] Run 0 - Step 475: val_loss=4.3183
[2025-12-08 16:51:14.180] [INFO] Run 0 - Step 500: val_loss=4.2922
[2025-12-08 16:52:25.538] [INFO] Run 0 - Step 525: val_loss=4.2755
[2025-12-08 16:53:36.529] [INFO] Run 0 - Step 550: val_loss=4.2497
[2025-12-08 16:54:48.053] [INFO] Run 0 - Step 575: val_loss=4.2253
[2025-12-08 16:55:59.897] [INFO] Run 0 - Step 600: val_loss=4.2116
[2025-12-08 16:57:11.645] [INFO] Run 0 - Step 625: val_loss=4.1938
[2025-12-08 16:58:23.281] [INFO] Run 0 - Step 650: val_loss=4.1724
[2025-12-08 16:59:35.080] [INFO] Run 0 - Step 675: val_loss=4.1595
[2025-12-08 17:00:46.850] [INFO] Run 0 - Step 700: val_loss=4.1484
[2025-12-08 17:01:58.121] [INFO] Run 0 - Step 725: val_loss=4.1284
[2025-12-08 17:03:09.183] [INFO] Run 0 - Step 750: val_loss=4.1092
[2025-12-08 17:04:20.728] [INFO] Run 0 - Step 775: val_loss=4.0943
[2025-12-08 17:05:32.354] [INFO] Run 0 - Step 800: val_loss=4.0521
[2025-12-08 17:06:43.601] [INFO] Run 0 - Step 825: val_loss=4.0277
[2025-12-08 17:07:54.559] [INFO] Run 0 - Step 850: val_loss=4.0040
[2025-12-08 17:09:06.032] [INFO] Run 0 - Step 875: val_loss=3.9790
[2025-12-08 17:10:17.758] [INFO] Run 0 - Step 900: val_loss=3.9569
[2025-12-08 17:11:29.560] [INFO] Run 0 - Step 925: val_loss=3.9348
[2025-12-08 17:12:41.423] [INFO] Run 0 - Step 950: val_loss=3.9180
[2025-12-08 17:13:53.200] [INFO] Run 0 - Step 975: val_loss=3.9040
[2025-12-08 17:15:04.937] [INFO] Run 0 - Step 1000: val_loss=3.8965
[2025-12-08 17:15:09.757] [INFO] Run 0 complete: val_loss=3.8965, train_loss=3.6948, time=3108.46s, seed=42
[2025-12-08 17:15:09.757] [INFO] Progress: 1/1 runs completed (1 successful)
[2025-12-08 17:15:09.758] [INFO] --------------------------------------------------------------------------------
[2025-12-08 17:15:09.758] [INFO] ================================================================================
[2025-12-08 17:15:09.758] [INFO] All runs completed: 1/1 successful
[2025-12-08 17:15:09.758] [INFO] ================================================================================
[2025-12-08 17:15:09.758] [INFO] Computing statistics...
[2025-12-08 17:15:09.758] [INFO] ================================================================================
[2025-12-08 17:15:09.758] [INFO] FINALIZING EXPERIMENT
[2025-12-08 17:15:09.758] [INFO] ================================================================================
[2025-12-08 17:15:09.771] [INFO] Experiment completed with 1 runs
[2025-12-08 17:15:09.771] [INFO] Successful runs: 1
[2025-12-08 17:15:09.771] [INFO] Failed runs: 0
[2025-12-08 17:15:09.771] [INFO] Mean validation loss: 3.8965 ± 0.0000
[2025-12-08 17:15:09.771] [INFO] Best validation loss: 3.8965
[2025-12-08 17:15:09.771] [INFO] Mean time per run: 3108.46s
[2025-12-08 17:15:09.771] [INFO] Total training time: 3108.46s (51.81 minutes)
[2025-12-08 17:15:09.772] [INFO] Summary saved to summary.json
[2025-12-08 17:15:09.772] [INFO] End Time: 2025-12-08 17:15:09.772256
[2025-12-08 17:15:09.772] [INFO] ================================================================================
[2025-12-08 17:15:09.772] [WARNING] ✗ Target validation loss NOT achieved: 3.8965 > 3.5000
